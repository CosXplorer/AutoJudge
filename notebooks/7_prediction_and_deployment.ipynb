{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3003079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1f0b7",
   "metadata": {},
   "source": [
    "***Loading All Models and Processors***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "401095f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LOADING MODELS\n",
      "==================================================\n",
      "✓ Classification model loaded\n",
      "✓ Regression model loaded\n",
      "✓ TF-IDF vectorizer loaded\n",
      "✓ Feature scaler loaded\n",
      "✓ Label encoder loaded\n",
      "✓ Feature names loaded\n",
      "\n",
      "All models and processors loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"LOADING MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Loading models\n",
    "with open(r'D:\\AutoJudge_v2\\models\\classification_model.pkl', 'rb') as f:\n",
    "    classification_model = pickle.load(f)\n",
    "print(\"✓ Classification model loaded\")\n",
    "\n",
    "with open(r'D:\\AutoJudge_v2\\models\\regression_model.pkl', 'rb') as f:\n",
    "    regression_model = pickle.load(f)\n",
    "print(\"✓ Regression model loaded\")\n",
    "\n",
    "# Loading preprocessing tools\n",
    "with open(r'D:\\AutoJudge_v2\\models\\tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "print(\"✓ TF-IDF vectorizer loaded\")\n",
    "\n",
    "with open(r'D:\\AutoJudge_v2\\models\\feature_scaler.pkl', 'rb') as f:\n",
    "    feature_scaler = pickle.load(f)\n",
    "print(\"✓ Feature scaler loaded\")\n",
    "\n",
    "with open(r'D:\\AutoJudge_v2\\models\\label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "print(\"✓ Label encoder loaded\")\n",
    "\n",
    "with open(r'D:\\AutoJudge_v2\\models\\feature_names.pkl', 'rb') as f:\n",
    "    feature_info = pickle.load(f)\n",
    "print(\"✓ Feature names loaded\")\n",
    "\n",
    "print(\"\\nAll models and processors loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ea38d",
   "metadata": {},
   "source": [
    "***Feature Extraction Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71535ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing extra whitespace\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return ''\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_manual_features(text):\n",
    "    \"\"\"Extract manual features from text\"\"\"\n",
    "    if pd.isna(text) or text == '':\n",
    "        return np.zeros(15)  # Return zeros for all manual features\n",
    "    \n",
    "    words = text.split()\n",
    "    text_lower = text.lower()\n",
    "    \n",
    "    # Basic features\n",
    "    char_count = len(text)\n",
    "    word_count = len(words)\n",
    "    sentence_count = len(re.findall(r'[.!?]+', text))\n",
    "    avg_word_length = np.mean([len(w) for w in words]) if words else 0\n",
    "    uppercase_count = sum(1 for c in text if c.isupper())\n",
    "    digit_count = sum(1 for c in text if c.isdigit())\n",
    "    \n",
    "    # Math features\n",
    "    math_symbol_count = len(re.findall(r'[+\\-*/=<>≤≥≠]', text))\n",
    "    equation_count = len(re.findall(r'\\$.*?\\$', text))\n",
    "    bracket_count = len(re.findall(r'[\\(\\)\\[\\]\\{\\}]', text))\n",
    "    dollar_sign_count = text.count('$')\n",
    "    \n",
    "    # Keyword features\n",
    "    graph_words = ['graph', 'node', 'edge', 'tree', 'dfs', 'bfs', 'dijkstra', 'spanning']\n",
    "    dp_words = ['dynamic', 'dp', 'memoization', 'optimal', 'subproblem', 'recursion']\n",
    "    sort_words = ['sort', 'sorted', 'order', 'arrange', 'ascending', 'descending']\n",
    "    ds_words = ['array', 'list', 'stack', 'queue', 'heap', 'hash', 'map', 'set']\n",
    "    complexity_words = ['O(n)', 'O(log n)', 'complexity', 'efficient', 'optimize', 'time limit']\n",
    "    \n",
    "    graph_keywords = sum(text_lower.count(w) for w in graph_words)\n",
    "    dp_keywords = sum(text_lower.count(w) for w in dp_words)\n",
    "    sorting_keywords = sum(text_lower.count(w) for w in sort_words)\n",
    "    data_structure_keywords = sum(text_lower.count(w) for w in ds_words)\n",
    "    complexity_keywords = sum(text_lower.count(w) for w in complexity_words)\n",
    "    \n",
    "    return np.array([\n",
    "        char_count, word_count, sentence_count, avg_word_length, \n",
    "        uppercase_count, digit_count, math_symbol_count, equation_count,\n",
    "        bracket_count, dollar_sign_count, graph_keywords, dp_keywords,\n",
    "        sorting_keywords, data_structure_keywords, complexity_keywords\n",
    "    ])\n",
    "\n",
    "def preprocess_problem(title, description, input_desc, output_desc):\n",
    "    \"\"\"Preprocess a new problem for prediction\"\"\"\n",
    "    # Clean texts\n",
    "    title = clean_text(title)\n",
    "    description = clean_text(description)\n",
    "    input_desc = clean_text(input_desc)\n",
    "    output_desc = clean_text(output_desc)\n",
    "    \n",
    "    # Combine text\n",
    "    combined_text = f\"{title} {description} {input_desc} {output_desc}\"\n",
    "    \n",
    "    # Extract manual features\n",
    "    manual_features = extract_manual_features(combined_text)\n",
    "    \n",
    "    # Extract TF-IDF features\n",
    "    tfidf_features = tfidf_vectorizer.transform([combined_text]).toarray()[0]\n",
    "    \n",
    "    # Scale manual features\n",
    "    manual_features_scaled = feature_scaler.transform(manual_features.reshape(1, -1))[0]\n",
    "    \n",
    "    # Combine features\n",
    "    all_features = np.concatenate([manual_features_scaled, tfidf_features])\n",
    "    \n",
    "    return all_features.reshape(1, -1)\n",
    "\n",
    "def predict_difficulty(title, description, input_desc, output_desc):\n",
    "    \"\"\"Predict both class and score for a problem\"\"\"\n",
    "    # Preprocess\n",
    "    features = preprocess_problem(title, description, input_desc, output_desc)\n",
    "    \n",
    "    # Predict class\n",
    "    class_encoded = classification_model.predict(features)[0]\n",
    "    class_label = label_encoder.inverse_transform([class_encoded])[0]\n",
    "    \n",
    "    # Get class probabilities (if available)\n",
    "    if hasattr(classification_model, 'predict_proba'):\n",
    "        class_probabilities = classification_model.predict_proba(features)[0]\n",
    "        class_probs_dict = {\n",
    "            label_encoder.inverse_transform([i])[0]: prob \n",
    "            for i, prob in enumerate(class_probabilities)\n",
    "        }\n",
    "    else:\n",
    "        class_probs_dict = None\n",
    "    \n",
    "    # Predict score\n",
    "    predicted_score = regression_model.predict(features)[0]\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': class_label,\n",
    "        'predicted_score': round(predicted_score, 2),\n",
    "        'class_probabilities': class_probs_dict\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83246e29",
   "metadata": {},
   "source": [
    "***Testing on Sample Problems***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e521d5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 1: Easy Problem\n",
      "Title: Sum of Two Numbers\n",
      "Predicted Class: medium\n",
      "Predicted Score: 4.52\n",
      "Class Probabilities:\n",
      "  easy: 0.160\n",
      "  hard: 0.296\n",
      "  medium: 0.544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample problem 1: Easy problem\n",
    "sample1 = {\n",
    "    'title': 'Sum of Two Numbers',\n",
    "    'description': 'Given two integers a and b, compute their sum.',\n",
    "    'input_desc': 'Two integers a and b separated by space.',\n",
    "    'output_desc': 'Print a single integer, the sum of a and b.'\n",
    "}\n",
    "\n",
    "print(\"\\nSample 1: Easy Problem\")\n",
    "print(f\"Title: {sample1['title']}\")\n",
    "result1 = predict_difficulty(**sample1)\n",
    "print(f\"Predicted Class: {result1['predicted_class']}\")\n",
    "print(f\"Predicted Score: {result1['predicted_score']}\")\n",
    "if result1['class_probabilities']:\n",
    "    print(\"Class Probabilities:\")\n",
    "    for cls, prob in result1['class_probabilities'].items():\n",
    "        print(f\"  {cls}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a70df6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample 2: Medium Problem\n",
      "Title: Binary Search\n",
      "Predicted Class: hard\n",
      "Predicted Score: 5.3\n",
      "Class Probabilities:\n",
      "  easy: 0.110\n",
      "  hard: 0.466\n",
      "  medium: 0.424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample problem 2: Medium problem\n",
    "sample2 = {\n",
    "    'title': 'Binary Search',\n",
    "    'description': 'Given a sorted array of n integers, find if a target value x exists. Use binary search algorithm.',\n",
    "    'input_desc': 'First line contains n and x. Second line contains n sorted integers.',\n",
    "    'output_desc': 'Print YES if x exists, otherwise NO.'\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"\\nSample 2: Medium Problem\")\n",
    "print(f\"Title: {sample2['title']}\")\n",
    "result2 = predict_difficulty(**sample2)\n",
    "print(f\"Predicted Class: {result2['predicted_class']}\")\n",
    "print(f\"Predicted Score: {result2['predicted_score']}\")\n",
    "if result2['class_probabilities']:\n",
    "    print(\"Class Probabilities:\")\n",
    "    for cls, prob in result2['class_probabilities'].items():\n",
    "        print(f\"  {cls}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2db63f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Sample 3: Hard Problem\n",
      "Title: Maximum Flow in Graph\n",
      "Predicted Class: hard\n",
      "Predicted Score: 6.67\n",
      "Class Probabilities:\n",
      "  easy: 0.037\n",
      "  hard: 0.844\n",
      "  medium: 0.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "d:\\AutoJudge_v2\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2691: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Sample problem 3: Hard problem\n",
    "sample3 = {\n",
    "    'title': 'Maximum Flow in Graph',\n",
    "    'description': 'Given a directed graph with edge capacities, find the maximum flow from source to sink using Ford-Fulkerson algorithm. The graph has n nodes and m edges. You need to implement an efficient solution with time complexity O(VE^2).',\n",
    "    'input_desc': 'First line: n, m, source, sink. Next m lines: u, v, capacity for each edge.',\n",
    "    'output_desc': 'Print a single integer - the maximum flow value.'\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"\\nSample 3: Hard Problem\")\n",
    "print(f\"Title: {sample3['title']}\")\n",
    "result3 = predict_difficulty(**sample3)\n",
    "print(f\"Predicted Class: {result3['predicted_class']}\")\n",
    "print(f\"Predicted Score: {result3['predicted_score']}\")\n",
    "if result3['class_probabilities']:\n",
    "    print(\"Class Probabilities:\")\n",
    "    for cls, prob in result3['class_probabilities'].items():\n",
    "        print(f\"  {cls}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764a561",
   "metadata": {},
   "source": [
    "***Batch Prediction Function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f33dc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(problems_df):\n",
    "    \"\"\"Predict for multiple problems at once\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in problems_df.iterrows():\n",
    "        result = predict_difficulty(\n",
    "            row['title'],\n",
    "            row['description'],\n",
    "            row['input_description'],\n",
    "            row['output_description']\n",
    "        )\n",
    "        results.append(result)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return pd.concat([problems_df.reset_index(drop=True), results_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e50d5",
   "metadata": {},
   "source": [
    "***Interactive Prediction Function***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2a63c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_prediction():\n",
    "    \"\"\"Interactive mode for single problem prediction\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"INTERACTIVE PREDICTION MODE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\nEnter problem details:\")\n",
    "    title = input(\"Title: \")\n",
    "    print(\"\\nDescription (press Enter twice when done):\")\n",
    "    description_lines = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        description_lines.append(line)\n",
    "    description = \" \".join(description_lines)\n",
    "    \n",
    "    print(\"\\nInput Description (press Enter twice when done):\")\n",
    "    input_lines = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        input_lines.append(line)\n",
    "    input_desc = \" \".join(input_lines)\n",
    "    \n",
    "    print(\"\\nOutput Description (press Enter twice when done):\")\n",
    "    output_lines = []\n",
    "    while True:\n",
    "        line = input()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        output_lines.append(line)\n",
    "    output_desc = \" \".join(output_lines)\n",
    "    \n",
    "    # Predict\n",
    "    result = predict_difficulty(title, description, input_desc, output_desc)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PREDICTION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nPredicted Class: {result['predicted_class'].upper()}\")\n",
    "    print(f\"Predicted Score: {result['predicted_score']}/10.0\")\n",
    "    \n",
    "    if result['class_probabilities']:\n",
    "        print(\"\\nClass Probabilities:\")\n",
    "        for cls, prob in result['class_probabilities'].items():\n",
    "            bar = \"█\" * int(prob * 50)\n",
    "            print(f\"  {cls:8s}: {bar} {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc1b2c8",
   "metadata": {},
   "source": [
    "***Model Performance Summary***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc5d98be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Model:\n",
      "  Model: Gradient Boosting\n",
      "  Test Accuracy: 0.6630\n",
      "\n",
      "Regression Model:\n",
      "  Model: Random Forest\n",
      "  Test MAE: 1.5578\n",
      "  Test RMSE: 1.9447\n",
      "  Test R² Score: 0.4840\n"
     ]
    }
   ],
   "source": [
    "# results\n",
    "with open(r'D:\\AutoJudge_v2\\models\\classification_results.pkl', 'rb') as f:\n",
    "    class_results = pickle.load(f)\n",
    "\n",
    "with open(r'D:\\AutoJudge_v2\\models\\regression_results.pkl', 'rb') as f:\n",
    "    reg_results = pickle.load(f)\n",
    "\n",
    "print(\"\\nClassification Model:\")\n",
    "print(f\"  Model: {class_results['model_name']}\")\n",
    "print(f\"  Test Accuracy: {class_results['test_accuracy']:.4f}\")\n",
    "\n",
    "print(\"\\nRegression Model:\")\n",
    "print(f\"  Model: {reg_results['model_name']}\")\n",
    "print(f\"  Test MAE: {reg_results['test_mae']:.4f}\")\n",
    "print(f\"  Test RMSE: {reg_results['test_rmse']:.4f}\")\n",
    "print(f\"  Test R² Score: {reg_results['test_r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646bdf3d",
   "metadata": {},
   "source": [
    "***Saving Prediction Pipeline***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1d5e0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Complete prediction pipeline saved to 'prediction_pipeline.pkl'\n",
      "\n",
      "==================================================\n",
      "READY FOR PREDICTIONS!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "prediction_pipeline = {\n",
    "    'classification_model': classification_model,\n",
    "    'regression_model': regression_model,\n",
    "    'tfidf_vectorizer': tfidf_vectorizer,\n",
    "    'feature_scaler': feature_scaler,\n",
    "    'label_encoder': label_encoder,\n",
    "    'predict_function': predict_difficulty\n",
    "}\n",
    "\n",
    "with open(r'D:\\AutoJudge_v2\\models\\prediction_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(prediction_pipeline, f)\n",
    "\n",
    "print(\"\\n✓ Complete prediction pipeline saved to 'prediction_pipeline.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"READY FOR PREDICTIONS!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
